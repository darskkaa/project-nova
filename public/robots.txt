# https://www.robotstxt.org/robotstxt.html
# Allow all web crawlers to access all parts of the site
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://yourdomain.com/sitemap.xml
Sitemap: https://yourdomain.com/server-sitemap.xml

# Crawl-delay parameter to limit the rate of requests
# Adjust this value based on your server capacity
Crawl-delay: 10

# Disallow access to admin and API routes
Disallow: /admin/
Disallow: /api/
Disallow: /_next/
Disallow: /*.json$
Disallow: /*?*

# Allow all image files for Google Images
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.png$
Allow: /*.gif$
Allow: /*.webp$

# Allow all CSS and JS files
Allow: /*.css$
Allow: /*.js$

# Host directive to specify the preferred domain
# Uncomment and replace with your domain
# Host: yourdomain.com

# Clean-param directive to avoid duplicate content
# Clean-param: ref /products/
# Clean-param: source /blog/
